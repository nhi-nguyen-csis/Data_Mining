# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vwKrfO3A2sb79ujFVo8rELKzoguY6n0-
"""

#-------------------------------------------------------------------------
# AUTHOR: Nhi Nguyen
# FILENAME: title of the source file
# SPECIFICATION: description of the program
# FOR: CS 5990- Assignment #3
# TIME SPENT: how long it took you to complete the assignment
#-----------------------------------------------------------*/
import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler


# helper func to decode the temperature
def decode_temperature(c):
  # initialize 11 classes after discretization
  classes = [i for i in range(-22, 40, 6)]
  for i, temp in enumerate(classes):
    if c < temp:
      return i
  return len(classes)

# helper func to make preprocessing
def preprocessing(df):
  # 1. drop date column and rename other columns
  df.drop('Formatted Date', axis=1, inplace=True)
  df = df.rename(columns={"Humidity": "humidity",
                          "Wind Speed (km/h)": "wind_speed",
                          'Wind Bearing (degrees)': 'wind_bearing',
                          'Visibility (km)': 'visibility',
                          'Pressure (millibars)': 'pressure',
                          'Temperature (C)': 'temperature'})
  # 2. classify temperature class
  df['temperature'] = df['temperature'].apply(decode_temperature)
  # 3. extract features and class from the dataset
  features = ['humidity', 'wind_speed', 'wind_bearing', 'visibility', 'pressure']
  X = df[features]
  y = df['temperature']
  return X, y

# reading the training data
df = pd.read_csv("/content/sample_data/weather_training.csv")
# reading the test data
test_df = pd.read_csv("/content/sample_data/weather_test.csv")

# preprocessing the training set and test set
X_train, y_train = preprocessing(df)
X_test, y_test = preprocessing(test_df)

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# defining the hyperparameter values of KNN
k_values = [i for i in range(1, 20)]
p_values = [1, 2]
w_values = ['uniform', 'distance']

highest_accuracy = 0

for k in k_values:
  for p in p_values:
    for w in w_values:
      #fitting the knn to the data
      clf = KNeighborsClassifier(n_neighbors=k, p=p, weights=w)
      clf = clf.fit(X_train, y_train)

      #make the KNN prediction for each test sample and start computing its accuracy
      #hint: to iterate over two collections simultaneously, use zip()
      #Example. for (x_testSample, y_testSample) in zip(X_test, y_test):
      total_correct = 0

      for (x_testSample, y_testSample) in zip(X_test, y_test):
      #to make a prediction do: clf.predict([x_testSample])
        y_pred = clf.predict([x_testSample])
        #the prediction should be considered correct if the output value is [-15%,+15%] distant from the real output values.
        #to calculate the % difference between the prediction and the real output values use: 100*(|predicted_value - real_value|)/real_value))
        #--> add your Python code here
        diff = 100*(abs(y_pred - y_testSample)) /y_testSample
        total_correct += 1 if diff <= 15 else 0

      # compute the current accuracy
      total_samples = len(X_test)
      accuracy = total_correct / total_samples

      #check if the calculated accuracy is higher than the previously one calculated. If so, update the highest accuracy and print it together
      #with the KNN hyperparameters. Example: "Highest KNN accuracy so far: 0.92, Parameters: k=1, p=2, w= 'uniform'"
      #--> add your Python code here
      if accuracy > highest_accuracy:
        highest_accuracy = accuracy
        print(f"Highest KNN accuracy so far: {highest_accuracy:.2f}, Parameters: k={k}, p={p}, w='{w}'")