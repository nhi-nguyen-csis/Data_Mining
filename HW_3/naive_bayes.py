# -*- coding: utf-8 -*-
"""Untitled38.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BjOjr1eWHsZZ9_RbXHuDrJ30AftwxR_E
"""

#-------------------------------------------------------------------------
# AUTHOR: Nhi Nguyen
# FILENAME: title of the source file
# SPECIFICATION: description of the program
# FOR: CS 5990- Assignment #3
# TIME SPENT: how long it took you to complete the assignment
#-----------------------------------------------------------*/
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.naive_bayes import GaussianNB


# helper func to decode the temperature
def decode_temperature(c):
  # initialize 11 classes after discretization
  classes = [i for i in range(-22, 40, 6)]
  for i, temp in enumerate(classes):
    if c < temp:
      return i
  return len(classes)

# helper func to make preprocessing
def preprocessing(df):
  # 1. drop date column and rename other columns
  df.drop('Formatted Date', axis=1, inplace=True)
  df = df.rename(columns={"Humidity": "humidity",
                          "Wind Speed (km/h)": "wind_speed",
                          'Wind Bearing (degrees)': 'wind_bearing',
                          'Visibility (km)': 'visibility',
                          'Pressure (millibars)': 'pressure',
                          'Temperature (C)': 'temperature'})
  # 2. classify temperature class
  df['temperature'] = df['temperature'].apply(decode_temperature)
  # 3. extract features and class from the dataset
  features = ['humidity', 'wind_speed', 'wind_bearing', 'visibility', 'pressure']
  X = df[features]
  y = df['temperature']
  return X, y

# reading the training data
#--> add your Python code here
df = pd.read_csv("/content/sample_data/weather_training.csv")
# reading the test data
test_df = pd.read_csv("/content/sample_data/weather_test.csv")

# preprocessing the training set and test set
# update the training + test class values according to the discretization (11 values only)
X_train, y_train = preprocessing(df)
X_test, y_test = preprocessing(test_df)

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#fitting the naive_bayes to the data
clf = GaussianNB()
clf.fit(X_train, y_train)

#make the naive_bayes prediction for each test sample and start computing its accuracy
#the prediction should be considered correct if the output value is [-15%,+15%] distant from the real output values
#to calculate the % difference between the prediction and the real output values use: 100*(|predicted_value - real_value|)/real_value))
#--> add your Python code here
total_correct = 0
for (x_testSample, y_testSample) in zip(X_test, y_test):
  y_pred = clf.predict([x_testSample])
  #the prediction should be considered correct if the output value is [-15%,+15%] distant from the real output values.
  #to calculate the % difference between the prediction and the real output values use: 100*(|predicted_value - real_value|)/real_value))
  #--> add your Python code here
  diff = 100*(abs(y_pred - y_testSample)) /y_testSample
  total_correct += 1 if diff <= 15 else 0

# compute the current accuracy
total_samples = len(X_test)
accuracy = total_correct / total_samples
#print the naive_bayes accuracyy
#--> add your Python code here
print(f"naive_bayes accuracy: {accuracy}")